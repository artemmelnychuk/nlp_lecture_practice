{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "MfuUsJv1o3HM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to install the necessary dependencies."
      ],
      "metadata": {
        "id": "8QAUgpqKo1Mq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEGRDJvcd9so"
      },
      "outputs": [],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to import the necessary packages."
      ],
      "metadata": {
        "id": "Vy2V7a_Zo85d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "import xgboost"
      ],
      "metadata": {
        "id": "xFgyL3h1ekrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "Ksmzu5qDkaay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's classify the sentiment (positive or negative) of movie reviews. For that, we will use the IMDB dataset, which contains 25,000 movie reviews from the Internet Movie Database (IMDB) and their sentiment labels. The dataset comes with the SHAP library."
      ],
      "metadata": {
        "id": "6EwHDQCohh8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = shap.datasets.imdb()"
      ],
      "metadata": {
        "id": "Dpe8pbiFiLrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at the dataset (X and y) to get a feeling for the data you are working with."
      ],
      "metadata": {
        "id": "eKzb7vy-iiG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Conduct a simple exploratory data analysis (EDA), e.g.,\n",
        "# 1. Print the size of the dataset (i.e., number of movie reviews)\n",
        "# 2. Print one movie review\n",
        "# 3. Print the labels\n",
        "# 4. Plot a histogram of the review lengths\n",
        "# 5. ..."
      ],
      "metadata": {
        "id": "x81v44gW4x3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset"
      ],
      "metadata": {
        "id": "aTuTS2i7p5kU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into a training and a test set. Use 20% of the examples for the test set."
      ],
      "metadata": {
        "id": "N9PAv0FrlbmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "d8qOdIjVldr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use TF-IDF representations to convert the text examples into a numeric word-count matrix."
      ],
      "metadata": {
        "id": "kZgSrPNlqEqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', min_df=10, max_features=1000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train).toarray() # .toarray() transforms the sparse matrix into a dense matrix to avoid issues with shap later on\n",
        "X_test_vec = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Print the dimensions of the resulting TF-IDF matrices\n",
        "print(\"Training Set:\", X_train_vec.shape)\n",
        "print(\"Test Set:\", X_test_vec.shape)"
      ],
      "metadata": {
        "id": "gtzxk2_lfYDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP for an XGBoost Model"
      ],
      "metadata": {
        "id": "TfzYT0lhqjmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate and fit an XGBClassifier model, i.e., a classifier based on decision trees."
      ],
      "metadata": {
        "id": "Zkoc_Sm6qld4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgboost.XGBClassifier()\n",
        "model.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "id": "Opslg_tngV_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate SHAP values using a shap.Explainer object. Then plot the SHAP values in a waterfall chart for a single movie review.\n",
        "\n",
        "Starting point: https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/waterfall.html"
      ],
      "metadata": {
        "id": "b_Lqfs2nrGxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Calculate SHAP values using a shap.Explainer object"
      ],
      "metadata": {
        "id": "QVme5Clx5w-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at a particular movie review. Also print its ground truth label and predicted label."
      ],
      "metadata": {
        "id": "64nTQBkx6Fwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 2\n",
        "\n",
        "print(\"Review Text:\\n\", X_test[index])\n",
        "print(f\"Ground Truth: {'POSITIVE' if y_test[index] else 'NEGATIVE'}\")\n",
        "print(f\"Model Prediction: {'POSITIVE' if model.predict([X_test_vec[index]])[0] == 1 else 'NEGATIVE'}\")"
      ],
      "metadata": {
        "id": "5FyPdE0-tQQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Plot a waterfall chart for that movie review using shap.plots.waterfall(...) and the calculated SHAP values"
      ],
      "metadata": {
        "id": "ljChjLy86B0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP for a Transformer-based Model"
      ],
      "metadata": {
        "id": "2vQ7RzLlvCWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's generate SHAP values for a Transformer-based sentiment classifier on the same dataset.\n",
        "\n",
        "Starting point: https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/sentiment_analysis/Positive%20vs.%20Negative%20Sentiment%20Classification.html"
      ],
      "metadata": {
        "id": "lo0IkA8vynUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "DP75VsfFTlZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Run a sentiment-analysis transformers pipeline"
      ],
      "metadata": {
        "id": "4VvDeWeZ6iQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Calculate SHAP values using a shap.Explainer object"
      ],
      "metadata": {
        "id": "7OCNaEPt6sm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Plot the SHAP values for a single moview review, e.g., using shap.plots.text(...) and the calculated SHAP values"
      ],
      "metadata": {
        "id": "gCJwg1Xf2fI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice Questions"
      ],
      "metadata": {
        "id": "aPAtl1_0eH8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Why are LLMs sometimes bad at solving multi-step reasoning problems? In general, how can we improve the performance of LLM-based problem-solving approaches on multi-step reasoning problems?\n",
        "2.   What are the advantages and disadvantages of using inherently transparent models? In which situation does it make sense, in which situations not?\n",
        "3.   How can we make LLMs produce a chain of reasoning steps to solve a complex problem through prompting alone, i.e., without fine-tuning the model?\n",
        "4.   How is Tree-of-Thoughts (ToT) different from Chain-of-Thought (CoT) and Input-Output/Standard Prompting (IO)? What kinds of problems can and cannot be solved with each technique?\n",
        "5.   When facing a knowledge-related problem or question that is difficult to understand, which LLM prompting technique can help in such cases?\n",
        "6.   When facing a clearly described problem or question where the correct answer is difficult to find, which LLM prompting technique can help in such cases?\n",
        "7.  What is the probability-faithfulness dilemma in XAI and how can LLM prompting techniques help to avoid or reduce it?"
      ],
      "metadata": {
        "id": "VQUAI6fbuTzI"
      }
    }
  ]
}